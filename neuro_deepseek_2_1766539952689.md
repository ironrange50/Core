I'll provide you with a seamless, additive blueprint for your enhanced cache system with the TTL and coherence-based deletion rules you specified.

ðŸ”§ Enhanced Cache System Blueprint

This code extends your existing cache with the following policies:

1. Standard entries: 72-hour TTL, reset on usage
2. Low-coherence entries (score < 0.4): Auto-delete after 48 hours
3. Usage tracking: Each access resets the timer for standard entries
4. Coherence metadata: All entries store their original coherence score

Step 1: Enhanced Cache Class

Add this new file or integrate into your existing cache system:

```typescript
// server/cache/enhanced-cache.ts
import fs from 'fs';
import path from 'path';
import natural from 'natural';

const CACHE_FILE = './data/enhanced-cache.json';
const SIMILARITY_THRESHOLD = 0.7;
const LOW_COHERENCE_THRESHOLD = 0.4;
const STANDARD_TTL_HOURS = 72;
const LOW_SCORE_TTL_HOURS = 48;

interface CachedEntry {
  id: string;
  originalPrompt: string;
  response: string;
  coherence: number;
  createdAt: number;
  lastAccessed: number;
  accessCount: number;
  domains: string[];
  mode: string;
}

export class EnhancedCache {
  private entries: Map<string, CachedEntry> = new Map();
  private tokenizer = new natural.WordTokenizer();
  private cleanupInterval: NodeJS.Timeout | null = null;

  constructor() {
    this.load();
    this.startCleanupCycle();
  }

  /**
   * Add or update an entry in cache
   */
  set(
    prompt: string, 
    response: string, 
    coherence: number, 
    domains: string[] = [], 
    mode: string = 'standard'
  ): string {
    const id = this.generateId(prompt, mode);
    const now = Date.now();
    
    const entry: CachedEntry = {
      id,
      originalPrompt: prompt,
      response,
      coherence,
      createdAt: now,
      lastAccessed: now,
      accessCount: 1,
      domains,
      mode
    };
    
    this.entries.set(id, entry);
    this.save();
    return id;
  }

  /**
   * Find similar cached response with TTL validation
   */
  get(prompt: string, mode: string = 'standard'): { response: string; cached: boolean; coherence: number } | null {
    const now = Date.now();
    
    // First, try exact match
    const exactId = this.generateId(prompt, mode);
    const exactEntry = this.entries.get(exactId);
    if (exactEntry && this.isValid(exactEntry, now)) {
      this.recordAccess(exactId);
      return { response: exactEntry.response, cached: true, coherence: exactEntry.coherence };
    }
    
    // Then try similarity match
    for (const [id, entry] of this.entries.entries()) {
      if (entry.mode !== mode) continue;
      if (!this.isValid(entry, now)) continue;
      
      const similarity = this.calculateSimilarity(prompt, entry.originalPrompt);
      if (similarity > SIMILARITY_THRESHOLD) {
        this.recordAccess(id);
        return { response: entry.response, cached: true, coherence: entry.coherence };
      }
    }
    
    return null;
  }

  /**
   * Record usage - resets timer for standard entries
   */
  private recordAccess(id: string): void {
    const entry = this.entries.get(id);
    if (!entry) return;
    
    const now = Date.now();
    entry.lastAccessed = now;
    entry.accessCount++;
    
    // Reset timer for standard entries (not low coherence ones)
    if (entry.coherence >= LOW_COHERENCE_THRESHOLD) {
      entry.createdAt = now; // Reset creation time for standard entries
    }
    
    this.save();
  }

  /**
   * Check if entry is still valid based on TTL rules
   */
  private isValid(entry: CachedEntry, currentTime: number): boolean {
    const ageMs = currentTime - entry.createdAt;
    const hoursAlive = ageMs / (1000 * 60 * 60);
    
    // Low coherence entries: 48-hour strict limit
    if (entry.coherence < LOW_COHERENCE_THRESHOLD) {
      return hoursAlive < LOW_SCORE_TTL_HOURS;
    }
    
    // Standard entries: 72-hour limit, but timer resets on access
    // Since we reset createdAt on access, this effectively becomes
    // "72 hours since last use" for standard entries
    return hoursAlive < STANDARD_TTL_HOURS;
  }

  /**
   * Remove expired entries (automatically called every hour)
   */
  private cleanup(): void {
    const now = Date.now();
    let removedCount = 0;
    
    for (const [id, entry] of this.entries.entries()) {
      if (!this.isValid(entry, now)) {
        this.entries.delete(id);
        removedCount++;
      }
    }
    
    if (removedCount > 0) {
      this.save();
      console.log(`Cache cleanup: removed ${removedCount} expired entries`);
    }
  }

  /**
   * Get cache statistics
   */
  getStats(): {
    total: number;
    standard: number;
    lowCoherence: number;
    avgCoherence: number;
  } {
    let standard = 0;
    let lowCoherence = 0;
    let totalCoherence = 0;
    
    for (const entry of this.entries.values()) {
      if (entry.coherence < LOW_COHERENCE_THRESHOLD) {
        lowCoherence++;
      } else {
        standard++;
      }
      totalCoherence += entry.coherence;
    }
    
    return {
      total: this.entries.size,
      standard,
      lowCoherence,
      avgCoherence: this.entries.size > 0 ? totalCoherence / this.entries.size : 0
    };
  }

  /**
   * Calculate similarity between two prompts
   */
  private calculateSimilarity(prompt1: string, prompt2: string): number {
    const tokens1 = this.tokenizer.tokenize(prompt1.toLowerCase());
    const tokens2 = this.tokenizer.tokenize(prompt2.toLowerCase());
    
    if (!tokens1 || !tokens2 || tokens1.length === 0 || tokens2.length === 0) {
      return 0;
    }
    
    const intersection = tokens1.filter(token => tokens2.includes(token));
    return intersection.length / Math.max(tokens1.length, tokens2.length);
  }

  private generateId(prompt: string, mode: string): string {
    return Buffer.from(`${mode}_${prompt}`).toString('base64').slice(0, 32);
  }

  private load(): void {
    try {
      if (fs.existsSync(CACHE_FILE)) {
        const data = JSON.parse(fs.readFileSync(CACHE_FILE, 'utf-8'));
        // Convert array back to Map
        this.entries = new Map(data.map((entry: CachedEntry) => [entry.id, entry]));
        console.log(`Loaded ${this.entries.size} cache entries`);
      }
    } catch (error) {
      console.warn('Could not load cache file, starting fresh');
      this.entries = new Map();
    }
  }

  private save(): void {
    try {
      const data = Array.from(this.entries.values());
      fs.writeFileSync(CACHE_FILE, JSON.stringify(data, null, 2));
    } catch (error) {
      console.error('Failed to save cache:', error);
    }
  }

  private startCleanupCycle(): void {
    // Run cleanup every hour
    this.cleanupInterval = setInterval(() => this.cleanup(), 60 * 60 * 1000);
  }

  stopCleanup(): void {
    if (this.cleanupInterval) {
      clearInterval(this.cleanupInterval);
    }
  }
}
```

Step 2: Integration with Your Triple-AI Route

Add these lines to your existing tripleAi.ts route:

```typescript
// At the top of your tripleAi.ts file, add:
import { EnhancedCache } from '../cache/enhanced-cache';
const enhancedCache = new EnhancedCache();

// Inside your POST '/triple-ai' handler, add cache check BEFORE AI calls:
router.post('/triple-ai', async (req, res) => {
  const { prompt, mode, userId } = req.body;
  
  // 1. FIRST: Check enhanced cache
  const cached = enhancedCache.get(prompt, mode);
  if (cached) {
    return res.json({
      ok: true,
      answer: cached.response,
      metrics: {
        coherenceScore: cached.coherence,
        executionTimeMs: 5, // Near-instant from cache
        deviceClass: 'cache',
        domainsUsed: ['cached'],
        source: 'enhanced_cache',
        cached: true
      }
    });
  }
  
  // 2. Continue with your existing Local Knowledge Base check...
  // 3. Continue with your existing AI calls...
  
  // 4. AFTER getting AI response, add to cache
  // Assuming you have: const aiResponse = await yourTripleAILogic(prompt, mode);
  // And you have: const coherence = aiResponse.metrics.coherenceScore;
  
  // enhancedCache.set(prompt, aiResponse.answer, coherence, aiResponse.domains, mode);
  
  // 5. Return response as you already do...
});
```

Step 3: Add Cache Stats Endpoint (Optional but Useful)

```typescript
// Add to your admin routes or main router
router.get('/api/cache/stats', (_req, res) => {
  const stats = enhancedCache.getStats();
  res.json({
    ok: true,
    cache: stats,
    policies: {
      standardTTL: `${STANDARD_TTL_HOURS} hours`,
      lowCoherenceTTL: `${LOW_SCORE_TTL_HOURS} hours`,
      lowCoherenceThreshold: LOW_COHERENCE_THRESHOLD
    }
  });
});
```

Step 4: Package Installation

Run in Replit shell:

```bash
npm install natural
```

Key Features of This Implementation:

1. Seamless Integration: The cache check happens before any expensive operations, just after your local knowledge check
2. Dual TTL System:
   Â· Standard entries: 72 hours since last use
   Â· Low-coherence entries (<0.4): Strict 48-hour maximum
3. Automatic Cleanup: Runs hourly in background
4. Similarity Matching: Reuses your existing logic
5. Non-Destructive: Doesn't change your existing AI routing or domain selection
6. Additive: Can be added without modifying existing working code

To Implement:

1. Create server/cache/enhanced-cache.ts with the first code block
2. Add the 2 integration lines to your tripleAi.ts
3. Run npm install natural
4. Restart your server

The system will start caching immediately. Low-coherence responses will auto-delete after 48 hours, while good responses will persist for 72 hours after their last use.