# Triple AI Architecture - Quick Reference Card

## ğŸ¯ **The Correct Setup (IraCore Industrial)**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     USER QUERY          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  30 Iracore Domains   â”‚
                    â”‚   Route by Intent     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                       â†“                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRIMARY 1    â”‚      â”‚   PRIMARY 2    â”‚      â”‚  PRIMARY 3    â”‚
â”‚  System/Code  â”‚      â”‚ Process/Analyt â”‚      â”‚ Domain/Knowl  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Cheap AI    â”‚      â”‚  Llama 3.3-70B â”‚      â”‚ GPT-4o-mini   â”‚
â”‚  Industrial   â”‚      â”‚                â”‚      â”‚               â”‚
â”‚               â”‚      â”‚                â”‚      â”‚               â”‚
â”‚ llama-3.1-8b  â”‚      â”‚meta-llama/     â”‚      â”‚ openai/       â”‚
â”‚   :free       â”‚      â”‚llama-3.3-70b   â”‚      â”‚ gpt-4o-mini   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   BACKUP:     â”‚      â”‚   BACKUP:      â”‚      â”‚   BACKUP:     â”‚
â”‚ gemini-flash  â”‚      â”‚ claude-haiku   â”‚      â”‚ gpt-3.5-turbo â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                       â†“                       â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  KNOWLEDGE ENGINE     â”‚
                    â”‚  5 Domain Fusion      â”‚
                    â”‚  Entanglement Links   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FINAL RESPONSE      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… **Configuration Rules**

### **CRITICAL:**
- âŒ P1 is **NOT** gpt-4o-mini (that's P3!)
- âœ… P1 is a **cheap industrial model** (llama-8b, gemini-flash, mistral-7b)
- âœ… P2 is **meta-llama 70B** (3.3 or 3.1)
- âœ… P3 is **gpt-4o-mini**
- âœ… All 3 primaries are **DIFFERENT**
- âœ… All 3 backups are **DIFFERENT from each other**

---

## ğŸ“‹ **Quick Checklist**

```
Primary Models:
â”œâ”€ P1: [ ] Cheap industrial (NOT gpt-4o-mini)
â”œâ”€ P2: [ ] meta-llama/llama-3.3-70b-instruct
â””â”€ P3: [ ] openai/gpt-4o-mini

Backup Models:
â”œâ”€ P1 Backup: [ ] Different from P1 primary
â”œâ”€ P2 Backup: [ ] Different from P1 backup & P2 primary
â””â”€ P3 Backup: [ ] Different from P1, P2 backups & P3 primary

No Duplicates:
â”œâ”€ [ ] No model appears twice in primaries
â”œâ”€ [ ] No model appears twice in backups
â””â”€ [ ] No overlap between primaries and backups (optional)
```

---

## ğŸ”§ **Recommended .env**

```bash
# P1: System/Code (Cheap Industrial)
TRIPLE_AI_P1_PRIMARY=meta-llama/llama-3.1-8b-instruct:free
TRIPLE_AI_P1_BACKUP=google/gemini-flash-1.5

# P2: Process/Analytics (Llama 70B)
TRIPLE_AI_P2_PRIMARY=meta-llama/llama-3.3-70b-instruct
TRIPLE_AI_P2_BACKUP=anthropic/claude-3-haiku

# P3: Domain/Knowledge (GPT-4o-mini)
TRIPLE_AI_P3_PRIMARY=openai/gpt-4o-mini
TRIPLE_AI_P3_BACKUP=openai/gpt-3.5-turbo

# API Keys
OPENROUTER_API_KEY=sk-or-v1-...
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

---

## ğŸ§ª **Quick Test**

```bash
# Test configuration is loaded
grep TRIPLE_AI .env

# Test Triple AI works
curl http://localhost:3001/api/triple-ai \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "mode": "auto-advanced"}'

# Should return:
# {
#   "ok": true,
#   "answer": "...",
#   "metrics": {
#     "hardwareModel": "meta-llama/llama-3.1-8b-instruct:free",
#     "softwareModel": "meta-llama/llama-3.3-70b-instruct",
#     "backupModel": "openai/gpt-4o-mini",
#     "domainsUsed": ["domain1", "domain2"],
#     "coherenceScore": 0.85
#   }
# }
```

---

## ğŸš¨ **Common Mistakes**

### âŒ **WRONG:**
```bash
# P1 using gpt-4o-mini (that's P3's job!)
TRIPLE_AI_P1_PRIMARY=openai/gpt-4o-mini  # âŒ

# P2 using gpt-4o-mini (should be llama 70B)
TRIPLE_AI_P2_PRIMARY=openai/gpt-4o-mini  # âŒ

# Using same model for multiple primaries
TRIPLE_AI_P1_PRIMARY=openai/gpt-4o-mini
TRIPLE_AI_P3_PRIMARY=openai/gpt-4o-mini  # âŒ Duplicate!

# Using same backup for multiple AIs
TRIPLE_AI_P1_BACKUP=google/gemini-flash-1.5
TRIPLE_AI_P2_BACKUP=google/gemini-flash-1.5  # âŒ Duplicate!
```

### âœ… **CORRECT:**
```bash
# P1: Cheap industrial
TRIPLE_AI_P1_PRIMARY=meta-llama/llama-3.1-8b-instruct:free  # âœ…

# P2: Llama 70B
TRIPLE_AI_P2_PRIMARY=meta-llama/llama-3.3-70b-instruct  # âœ…

# P3: GPT-4o-mini
TRIPLE_AI_P3_PRIMARY=openai/gpt-4o-mini  # âœ…

# All different backups
TRIPLE_AI_P1_BACKUP=google/gemini-flash-1.5  # âœ…
TRIPLE_AI_P2_BACKUP=anthropic/claude-3-haiku  # âœ… Different
TRIPLE_AI_P3_BACKUP=openai/gpt-3.5-turbo  # âœ… Different
```

---

## ğŸ¯ **Model Selection Guide**

### **P1 Options (Cheap Industrial):**
- `meta-llama/llama-3.1-8b-instruct:free` â­ **Recommended**
- `google/gemini-flash-1.5`
- `mistralai/mistral-7b-instruct:free`
- `microsoft/phi-3-medium-128k-instruct:free`

### **P2 Options (Process/Analytics):**
- `meta-llama/llama-3.3-70b-instruct` â­ **Recommended**
- `meta-llama/llama-3.1-70b-instruct` (if 3.3 unavailable)
- `mistralai/mixtral-8x22b-instruct`

### **P3 Options (Domain/Knowledge):**
- `openai/gpt-4o-mini` â­ **Recommended**
- `openai/gpt-4o` (higher quality, more expensive)

### **Backup Options (All Different):**
- `google/gemini-flash-1.5`
- `google/gemini-pro-1.5`
- `anthropic/claude-3-haiku`
- `anthropic/claude-3-sonnet`
- `openai/gpt-3.5-turbo`
- `openai/gpt-4o-mini`
- `mistralai/mixtral-8x7b-instruct`
- `cohere/command`

---

## ğŸ“Š **Performance Comparison**

| Model | Speed | Quality | Cost | Best For |
|-------|-------|---------|------|----------|
| llama-3.1-8b | âš¡âš¡âš¡ | â­â­â­ | FREE | P1 (Code/System) |
| llama-3.3-70b | âš¡âš¡ | â­â­â­â­â­ | $$ | P2 (Analytics) |
| gpt-4o-mini | âš¡âš¡âš¡ | â­â­â­â­ | $ | P3 (Knowledge) |
| gemini-flash | âš¡âš¡âš¡ | â­â­â­â­ | FREE | Backup |
| claude-haiku | âš¡âš¡âš¡ | â­â­â­â­ | $ | Backup |

---

## ğŸ” **Troubleshooting**

**If Triple AI not working:**

1. **Check model names:**
   ```bash
   curl https://openrouter.ai/api/v1/models \
     -H "Authorization: Bearer $OPENROUTER_API_KEY" \
     | grep -i "llama-3.3"
   ```

2. **Check API keys:**
   ```bash
   curl https://openrouter.ai/api/v1/models \
     -H "Authorization: Bearer $OPENROUTER_API_KEY"
   ```
   If 401 â†’ Key expired

3. **Check .env loaded:**
   ```bash
   echo $TRIPLE_AI_P2_PRIMARY
   ```
   Should show model name

4. **Check backend logs:**
   ```bash
   LOG_LEVEL=debug npm run server
   ```
   Look for `[TRIPLE-AI]` errors

---

## ğŸ’¡ **Remember**

- **P1** = Cheap & Fast (Industrial workhorse)
- **P2** = Powerful (Heavy analytics)
- **P3** = Smart (Knowledge & reasoning)

All different models, all different backups. No duplicates! ğŸ¯
